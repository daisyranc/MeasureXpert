
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MeasureXpert</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="has-text-centered">
        <h1 class="title is-1">MeasureXpert: Automatic Anthropometric Measurement Extraction from Two Unregistered, Partial, Posed, and Dressed Body Scans</h1>
        <div class="is-size-5 publication-authors">
          <p>
            <a href="http://bmkitmef.etrovub.be/RanZhao">Ran Zhao</a><sup>1</sup>,
            <a href="http://bmkitmef.etrovub.be/XinxinDai">Xinxin Dai</a><sup>1</sup>,
            <a href="https://ai4engineeringlab.netlify.app/author/pengpeng-hu/">Pengpeng Hu</a><sup>2</sup>,
            <a href="https://pureportal.coventry.ac.uk/en/persons/vasile-palade">Vasile Palade</a><sup>3</sup>,
            <a href="http://bmkitmef.etrovub.be/AdrianMunteanu">Adrian Munteanu</a><sup>1</sup>,
          </p>
          <p><sup>1</sup>Vrije Universiteit Brussel, <sup>2</sup>The University of Manchester</p>,<sup>3</sup>Coventry University</p>
        </div>
        <div class="publication-links" style="margin-top: 1em;">
          <a href="https://www.researchgate.net/publication/393870669_MeasureXpert_Automatic_Anthropometric_Measurement_Extraction_from_Two_Unregistered_Partial_Posed_and_Dressed_Body_Scans" class="button is-dark is-rounded">üìÑ Paper</a>
          <a href="https://youtu.be/nTLO5dTdV1A" class="button is-dark is-rounded">‚ñ∂Ô∏è Video</a>
          <a href="https://github.com/daisyranc/MeasureXpert" class="button is-dark is-rounded">üíª Code</a>
          <a href="https://github.com/daisyranc/MeasureXpert/releases/tag/dataset" class="button is-dark is-rounded">üóÇ Data</a>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/nTLO5dTdV1A" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>

    <br><br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While automatic anthropometric measurement extraction has witnessed growth in recent years, effective, non-contact, and precise measurement methods for dressed humans in arbitrary poses are still lacking, limiting the widespread application of this technology. 
The occlusion caused by clothing and the adverse influence of posture on body shape significantly increase the complexity of this task. 
Additionally, current methods often assume the availability of a complete 3D body mesh in a canonical pose (e.g., "A" or "T" pose), which is not always the case in practice. To address these challenges, we propose MeasureXpert, a novel learning-based model that requires only two unregistered, partial, and dressed body scans as input, and accommodates entirely independent and arbitrary poses for each scan. MeasureXpert computes a comprehensive representation of the naked body shape by synergistically fusing features from the front- and back-view partial point clouds. The comprehensive representation obtained is mapped onto a 3D undressed body shape space, assuming a canonical posture and incorporating predefined measurement landmarks. A point-based offset optimization is also developed to refine the reconstructed complete body shape, enabling accurate regression of measurement values. To train the proposed model, a new large-scale dataset,
consisting of 300K samples, was synthesized. The proposed model was validated using two publicly available real-world datasets and was compared with different relevant methods.
Extensive experimental results demonstrate that MeasureXpert
achieves superior performance compared to the reference methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhao2025measurexpert,
  author    = {Ran Zhao, Xinxin Dai, Pengpeng Hu, Vasile Palade, Adrian Munteanu},
  title     = {MeasureXpert: Automatic Anthropometric Measurement Extraction from Two Unregistered, Partial, Posed, and Dressed Body Scans},
  journal   = {ICCV},
  year      = {2025},
}</code></pre>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4">More Our Related Works</h2>
    <div class="content">
      <ul>
        <li><a href="https://www.researchgate.net/publication/368395777_PoseNormNet_Identity-preserved_Posture_Normalization_of_3D_Body_Scans_in_Arbitrary_Postures" target="_blank">PoseNormNet: Identity-Preserved Posture Normalization of 3-D Body Scans in Arbitrary Postures</a></li>
        <li><a href="https://www.researchgate.net/publication/372563042_W2H-Net_Fast_Prediction_of_Waist-to-Hip_Ratio_from_Single_Partial_Dressed_Body_Scans_in_Arbitrary_Postures_via_Deep_Learning" target="_blank">W2H-Net: Fast prediction of waist-to-hip ratio from single partial dressed body scans in arbitrary postures via deep learning</a></li>
        <li><a href="https://www.researchgate.net/publication/371165564_Point2PartVolume_Human_Body_Volume_Estimation_from_A_Single_Depth_Image" target="_blank">Point2partvolume: Human body volume estimation from a single depth image</a></li>
        <li><a href="https://www.researchgate.net/publication/371760359_Measure4DHand_Dynamic_Hand_Measurement_Extraction_from_4D_Scans" target="_blank">Measure4dhand: Dynamic Hand Measurement Extraction from 4D Scans</a></li>
        <li><a href="https://www.researchgate.net/publication/369862571_A_Deep-Learning-Based_Approach_to_Automatically_Measuring_Foots_From_a_3D_Scan" target="_blank">A Deep-learning-based Approach to Automatically Measuring Foots from a 3D scan</a></li>
        <li><a href="https://www.researchgate.net/publication/358853840_Automatic_and_Fast_Extraction_of_3D_Hand_Measurements_using_a_Deep_Neural_Network" target="_blank">Automatic and fast extraction of 3d hand measurements using a deep neural network</a></li>
        <li><a href="https://www.researchgate.net/publication/356640890_Anet_A_Deep_Neural_Network_for_Automatic_3D_Anthropometric_Measurement_Extraction" target="_blank">Anet: A deep neural network for automatic 3d anthropometric measurement extraction</a></li>
        <li><a href="https://www.researchgate.net/publication/354051201_Deep_Learning-Based_Automated_Extraction_of_Anthropometric_Measurements_From_a_Single_3-D_Scan" target="_blank">Deep learning-based automated extraction of anthropometric measurements from a single 3-D scan</a></li>
      </ul>
    </div>
  </div>
</section>

</body>
</html>
